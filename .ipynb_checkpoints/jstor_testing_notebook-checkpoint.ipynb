{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory Matters:\n",
    "\n",
    "Here in this notebook we're going to do a little bit of work with the JSTOR Constellate [data builder](https://constellate.org/builder). I started by searching \"free speech\" and \"First Amendment\" as keywords, grabbing all the \"full text\" document types within the \"Law\" category. Constellate also has a nice feature that gives assigns a \"Dataset ID\" to each of the datasets one builds. The one for this project is \"b7adbb84-6bec-549e-83bb-11aeb045e5f9\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting our Libraries Imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import circlify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data:\n",
    "\n",
    "I simply downloaded the built dataset to my local machine (other options for loading the dataset are available [here](https://constellate.org/tutorials/exploring-metadata)—the downloaded  file comes as a `.gz` file, so we need to open that up with the handy [`gzip` library](https://docs.python.org/3/library/gzip.html). We want to do a little bit of work with [`pandas`](https://pandas.pydata.org/docs/) here (we could work, of course, just with the standard `json` library, but we're going to want to do some manipulation on the data and pandas is perfecty suited for that). So let's get the file opened and into a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(gzip.open('law_full.jsonl.gz'), lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial inspection of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>datePublished</th>\n",
       "      <th>docSubType</th>\n",
       "      <th>docType</th>\n",
       "      <th>fullText</th>\n",
       "      <th>id</th>\n",
       "      <th>identifier</th>\n",
       "      <th>isPartOf</th>\n",
       "      <th>issueNumber</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>unigramCount</th>\n",
       "      <th>bigramCount</th>\n",
       "      <th>trigramCount</th>\n",
       "      <th>abstract</th>\n",
       "      <th>collection</th>\n",
       "      <th>editor</th>\n",
       "      <th>hasPartTitle</th>\n",
       "      <th>keyphrase</th>\n",
       "      <th>subTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Thomas Reed Powell]</td>\n",
       "      <td>1922-01-01</td>\n",
       "      <td>research-article</td>\n",
       "      <td>article</td>\n",
       "      <td>[MICHIGAN LAW REVIEW VOL. XX JANUARY, 1922 No....</td>\n",
       "      <td>http://www.jstor.org/stable/1277162</td>\n",
       "      <td>[{'name': 'issn', 'value': '00262234'}, {'name...</td>\n",
       "      <td>Michigan Law Review</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[eng]</td>\n",
       "      <td>...</td>\n",
       "      <td>11348</td>\n",
       "      <td>{'denied.': 1, 'opposing': 3, 'take': 5, 'retr...</td>\n",
       "      <td>{'basis of': 1, 'in 69': 2, 'once the': 1, 'in...</td>\n",
       "      <td>{'manufacturing or domestic': 1, 'Prices of Co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Elizabeth Goitein, Faiza Patel]</td>\n",
       "      <td>2020-10-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>report</td>\n",
       "      <td>[TRANSITION 2020–2021 A Presidential Agenda fo...</td>\n",
       "      <td>http://www.jstor.org/stable/resrep28426</td>\n",
       "      <td>[{'name': 'local_uuid', 'value': '3dbcbae0-0d2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[eng]</td>\n",
       "      <td>...</td>\n",
       "      <td>13697</td>\n",
       "      <td>{'MacArthur': 1, 'secrecy,': 1, 'com/infectiou...</td>\n",
       "      <td>{'that individuals': 1, 'for FY': 1, 'end, the...</td>\n",
       "      <td>{'Amendment, and the': 1, '10 values of': 1, '...</td>\n",
       "      <td>American democracy urgently needs renewal. In ...</td>\n",
       "      <td>[Research Reports]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[H. R. M.]</td>\n",
       "      <td>1922-09-01</td>\n",
       "      <td>research-article</td>\n",
       "      <td>article</td>\n",
       "      <td>[512 10 CALIFORNIA LAW REVIEW CRIMINAL LAW: CR...</td>\n",
       "      <td>http://www.jstor.org/stable/3474218</td>\n",
       "      <td>[{'name': 'issn', 'value': '00081221'}, {'name...</td>\n",
       "      <td>California Law Review</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[eng]</td>\n",
       "      <td>...</td>\n",
       "      <td>4012</td>\n",
       "      <td>{'acts.': 2, 'stolen.': 1, '45': 1, 'proponent...</td>\n",
       "      <td>{'in Abrams': 1, 'tendencies. According': 1, '...</td>\n",
       "      <td>{'check is necessary': 1, 'opposition to organ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Alex Molnar, Faith Boninger, Gary Wilkinson, ...</td>\n",
       "      <td>2010-12-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>report</td>\n",
       "      <td>[EFFECTIVELY EMBEDDED SCHOOLS AND THE MACHINER...</td>\n",
       "      <td>http://www.jstor.org/stable/resrep42044</td>\n",
       "      <td>[{'name': 'local_uuid', 'value': '4df59bdd-9e8...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[eng]</td>\n",
       "      <td>...</td>\n",
       "      <td>16250</td>\n",
       "      <td>{'Modern': 1, 'contests,': 2, 'fact,': 4, 'Che...</td>\n",
       "      <td>{'and Faith': 2, 'Michelle Obama': 1, '(Contin...</td>\n",
       "      <td>{'(2009). Age of': 1, 'In modern society,': 1,...</td>\n",
       "      <td>In the context of the last two years’ recessio...</td>\n",
       "      <td>[Research Reports]</td>\n",
       "      <td>[Kevin Welner]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Thomas Raeburn White]</td>\n",
       "      <td>1904-01-01</td>\n",
       "      <td>research-article</td>\n",
       "      <td>article</td>\n",
       "      <td>[THE AMERICAN LAW REGISTER FOUNDED 1852 UNIVER...</td>\n",
       "      <td>http://www.jstor.org/stable/3306378</td>\n",
       "      <td>[{'name': 'issn', 'value': '15583562'}, {'name...</td>\n",
       "      <td>The American Law Register (1898-1907)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[eng]</td>\n",
       "      <td>...</td>\n",
       "      <td>7567</td>\n",
       "      <td>{'contrary,': 1, 'scandalous': 1, 'thought': 4...</td>\n",
       "      <td>{'supposition is': 1, 'publications, however':...</td>\n",
       "      <td>{'believing in the': 1, 'the institution of': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             creator datePublished  \\\n",
       "0                               [Thomas Reed Powell]    1922-01-01   \n",
       "1                   [Elizabeth Goitein, Faiza Patel]    2020-10-22   \n",
       "2                                         [H. R. M.]    1922-09-01   \n",
       "3  [Alex Molnar, Faith Boninger, Gary Wilkinson, ...    2010-12-02   \n",
       "4                             [Thomas Raeburn White]    1904-01-01   \n",
       "\n",
       "         docSubType  docType  \\\n",
       "0  research-article  article   \n",
       "1               NaN   report   \n",
       "2  research-article  article   \n",
       "3               NaN   report   \n",
       "4  research-article  article   \n",
       "\n",
       "                                            fullText  \\\n",
       "0  [MICHIGAN LAW REVIEW VOL. XX JANUARY, 1922 No....   \n",
       "1  [TRANSITION 2020–2021 A Presidential Agenda fo...   \n",
       "2  [512 10 CALIFORNIA LAW REVIEW CRIMINAL LAW: CR...   \n",
       "3  [EFFECTIVELY EMBEDDED SCHOOLS AND THE MACHINER...   \n",
       "4  [THE AMERICAN LAW REGISTER FOUNDED 1852 UNIVER...   \n",
       "\n",
       "                                        id  \\\n",
       "0      http://www.jstor.org/stable/1277162   \n",
       "1  http://www.jstor.org/stable/resrep28426   \n",
       "2      http://www.jstor.org/stable/3474218   \n",
       "3  http://www.jstor.org/stable/resrep42044   \n",
       "4      http://www.jstor.org/stable/3306378   \n",
       "\n",
       "                                          identifier  \\\n",
       "0  [{'name': 'issn', 'value': '00262234'}, {'name...   \n",
       "1  [{'name': 'local_uuid', 'value': '3dbcbae0-0d2...   \n",
       "2  [{'name': 'issn', 'value': '00081221'}, {'name...   \n",
       "3  [{'name': 'local_uuid', 'value': '4df59bdd-9e8...   \n",
       "4  [{'name': 'issn', 'value': '15583562'}, {'name...   \n",
       "\n",
       "                                isPartOf  issueNumber language  ... wordCount  \\\n",
       "0                    Michigan Law Review          3.0    [eng]  ...     11348   \n",
       "1                                    NaN          NaN    [eng]  ...     13697   \n",
       "2                  California Law Review          6.0    [eng]  ...      4012   \n",
       "3                                    NaN          NaN    [eng]  ...     16250   \n",
       "4  The American Law Register (1898-1907)          1.0    [eng]  ...      7567   \n",
       "\n",
       "                                        unigramCount  \\\n",
       "0  {'denied.': 1, 'opposing': 3, 'take': 5, 'retr...   \n",
       "1  {'MacArthur': 1, 'secrecy,': 1, 'com/infectiou...   \n",
       "2  {'acts.': 2, 'stolen.': 1, '45': 1, 'proponent...   \n",
       "3  {'Modern': 1, 'contests,': 2, 'fact,': 4, 'Che...   \n",
       "4  {'contrary,': 1, 'scandalous': 1, 'thought': 4...   \n",
       "\n",
       "                                         bigramCount  \\\n",
       "0  {'basis of': 1, 'in 69': 2, 'once the': 1, 'in...   \n",
       "1  {'that individuals': 1, 'for FY': 1, 'end, the...   \n",
       "2  {'in Abrams': 1, 'tendencies. According': 1, '...   \n",
       "3  {'and Faith': 2, 'Michelle Obama': 1, '(Contin...   \n",
       "4  {'supposition is': 1, 'publications, however':...   \n",
       "\n",
       "                                        trigramCount  \\\n",
       "0  {'manufacturing or domestic': 1, 'Prices of Co...   \n",
       "1  {'Amendment, and the': 1, '10 values of': 1, '...   \n",
       "2  {'check is necessary': 1, 'opposition to organ...   \n",
       "3  {'(2009). Age of': 1, 'In modern society,': 1,...   \n",
       "4  {'believing in the': 1, 'the institution of': ...   \n",
       "\n",
       "                                            abstract          collection  \\\n",
       "0                                                NaN                 NaN   \n",
       "1  American democracy urgently needs renewal. In ...  [Research Reports]   \n",
       "2                                                NaN                 NaN   \n",
       "3  In the context of the last two years’ recessio...  [Research Reports]   \n",
       "4                                                NaN                 NaN   \n",
       "\n",
       "           editor hasPartTitle keyphrase subTitle  \n",
       "0             NaN          NaN       NaN      NaN  \n",
       "1             NaN          NaN       NaN      NaN  \n",
       "2             NaN          NaN       NaN      NaN  \n",
       "3  [Kevin Welner]          NaN       NaN      NaN  \n",
       "4             NaN          NaN       NaN      NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a dataframe with 33 different columns, we can get a full list of column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['creator', 'datePublished', 'docSubType', 'docType', 'fullText', 'id',\n",
       "       'identifier', 'isPartOf', 'issueNumber', 'language', 'outputFormat',\n",
       "       'pageCount', 'pageEnd', 'pageStart', 'pagination', 'provider',\n",
       "       'publicationYear', 'publisher', 'sourceCategory', 'tdmCategory',\n",
       "       'title', 'url', 'volumeNumber', 'wordCount', 'unigramCount',\n",
       "       'bigramCount', 'trigramCount', 'abstract', 'collection', 'editor',\n",
       "       'hasPartTitle', 'keyphrase', 'subTitle'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're interested in potentially visualizing word counts in a way that provides a sligtht tweak on the good ol' Word Cloud, the `fullText` column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [MICHIGAN LAW REVIEW VOL. XX JANUARY, 1922 No....\n",
       "1    [TRANSITION 2020–2021 A Presidential Agenda fo...\n",
       "2    [512 10 CALIFORNIA LAW REVIEW CRIMINAL LAW: CR...\n",
       "3    [EFFECTIVELY EMBEDDED SCHOOLS AND THE MACHINER...\n",
       "4    [THE AMERICAN LAW REGISTER FOUNDED 1852 UNIVER...\n",
       "Name: fullText, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fullText'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_a_dictionary_by_values(dictionary):\n",
    "    sorted_dict = sorted(dictionary.items(), key=lambda x: x[1], reverse=True)\n",
    "    return(sorted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sorted_unigram_dict'] = df['unigramCount'].apply(sort_a_dictionary_by_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['unigramCount', 'bigramCount', 'trigramCount']\n",
    "for column in columns:\n",
    "    df[f\"sorted_{column}_dict\"] = df[column].apply(sort_a_dictionary_by_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.sort_values(by='wordCount', ascending=False).reset_index()\n",
    "print(df2['wordCount'].head())\n",
    "print(df2.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_word_cloud(dict_values):\n",
    "\n",
    "    wordcloud = WordCloud(width=1000, height=600, max_words=100, random_state=1, background_color='gray', colormap='plasma', collocations=False, stopwords=STOPWORDS).generate_from_frequencies(dict_values)\n",
    "    plt.figure(figsize=(40, 30))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_word_cloud(df['unigramCount'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "stop_words = set(STOPWORDS)\n",
    "\n",
    "def create_df(input):\n",
    "    list_words = input.split(' ')\n",
    "    set_words_full = list(set(list_words))\n",
    "\n",
    "    set_words = [i for i in set_words_full if i not in stop_words]\n",
    "    count_words = [list_words.count(i) for i in set_words]\n",
    "\n",
    "    df = pd.DataFrame(zip(set_words, count_words), columns=['words', 'count'])\n",
    "    df.sort_values('count', ascending=False, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_dict(palette, number, start):\n",
    "    pal = list(sns.color_palette(palette=palette, n_colors=number).as_hex())\n",
    "    color_d = dict(enumerate(pal, start=start))\n",
    "    return color_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "df_of_interest = df.iloc[0]\n",
    "print(df_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text_of_interest = df_of_interest['fullText']\n",
    "full_string = \" \".join(full_text_of_interest)\n",
    "print(full_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_words = full_string.split(' ')\n",
    "list_words_lower = [x.lower() for x in list_words]\n",
    "set_words_full = list(set(list_words_lower))\n",
    "set_words = [i for i in set_words_full if i not in stop_words]\n",
    "count_words = [list_words.count(i) for i in set_words]\n",
    "\n",
    "df = pd.DataFrame(zip(set_words, count_words), columns=['words', 'counts'])\n",
    "df.sort_values('counts', ascending=False, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see below that \"The\" is showing up here, which means the stopwords of WordCloud isn't picking it up. If we print out the stop_words list we get the following:\n",
    "\n",
    "print(stop_words)\n",
    "\n",
    "# So we can handle this in a couple of different ways ... we could add \"The\" to the list of stop words (following https://stackoverflow.com/questions/53997443/how-to-add-extra-stop-words-in-addition-to-default-stopwords-in-wordcloud):\n",
    "\n",
    "stop_words.add('The')\n",
    "stop_words.add('THE')\n",
    "\n",
    "print(stop_words)\n",
    "\n",
    "# Of course, the simpler way is probably to simply convert all the words to lower case:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_full_string = re.sub('[^A-Za-z0-9°]+', ' ', full_string)\n",
    "\n",
    "counts_df = create_df(full_string)\n",
    "counts_df['length'] = df.words.str.len()\n",
    "counts_df = counts_df[counts_df.length > 2]\n",
    "counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see below that \"The\" is showing up here, which means the stopwords of WordCloud isn't picking it up. If we print out the stop_words list we get the following:\n",
    "\n",
    "print(stop_words)\n",
    "\n",
    "# So we can handle this in a couple of different ways ... we could add \"The\" to the list of stop words (following https://stackoverflow.com/questions/53997443/how-to-add-extra-stop-words-in-addition-to-default-stopwords-in-wordcloud):\n",
    "\n",
    "stop_words = stop_words.add(['The', '\"The'])\n",
    "print(stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = [[i[0], i[-1]+1] for i in np.array_split(range(100), 5)]\n",
    "\n",
    "n = counts_df['count'].max()\n",
    "color_dict = get_color_dict('plasma', n, 1)\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(16, 8), facecolor='white', squeeze=False)\n",
    "for col, idx in zip(range(0, 5), index_list):\n",
    "    df = counts_df[idx[0]:idx[-1]]\n",
    "    label = [w + ': ' + str(n) for w, n in zip(df['words'], df['count'])]\n",
    "    color_l = [color_dict.get(i) for i in df['count']]\n",
    "    x = list(df['count'])\n",
    "    y = list(range(0, 20))\n",
    "\n",
    "    sns.barplot(x = x, y = y, data=df, alpha=0.9, orient='h', ax = axs[0][col], palette=color_l)\n",
    "    axs[0][col].set_xlim(0, n+1)\n",
    "    axs[0][col].set_yticklabels(label, fontsize=12)\n",
    "    axs[0][col].spines['bottom'].set_color('white')\n",
    "    axs[0][col].spines['right'].set_color('white')\n",
    "    axs[0][col].spines['left'].set_color('white')\n",
    "    axs[0][col].spines['top'].set_color('white')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = [[i[0], i[-1]+1] for i in np.array_split(range(100), 5)]\n",
    "print(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = counts_df['count'].max()\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, idx in zip(range(0, 5), index_list):\n",
    "    print(col, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = counts_df[idx[0]:idx[-1]]\n",
    "print(len(df))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dictionary = {\n",
    "    'word': ['hello', 'goodbye', 'howdy', 'happy day!'], \n",
    "    'count': [56, 87, 100, 25]\n",
    "    }\n",
    "\n",
    "test_df = pd.DataFrame(test_dictionary)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = [[i[0], i[-1]+1] for i in np.array_split(range(150), 5)]\n",
    "print(index_list)\n",
    "\n",
    "n = test_df['count'].max()\n",
    "color_dict = get_color_dict('plasma', n, 1)\n",
    "#print(test_df)\n",
    "test_range = range(0, 5)\n",
    "'''\n",
    "for col, idx in zip(test_range, index_list):\n",
    "    label = [w + ': ' + str(n) for w, n in zip(test_df['word'], test_df['count'])]\n",
    "    color_l = [color_dict.get(i) for i in df['count']]\n",
    "    x = list(test_df['count'])\n",
    "    y = list(range(0, 20))\n",
    "'''\n",
    "x = list(test_df['count'])\n",
    "y = list(range(0, 20))\n",
    "sns.barplot(x = 'word', y = 'count', data=test_df, alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(counts_df))\n",
    "ax = sns.barplot(x = 'words', y = 'count', data=counts_df.iloc[0:100], alpha=0.5)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = [[i[0], i[-1]+1] for i in np.array_split(range(100), 5)]\n",
    "print(index_list)\n",
    "n = counts_df['count'].max()\n",
    "color_dict = get_color_dict('plasma', n, 1)\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(16, 8), facecolor='white', squeeze=False)\n",
    "for col, idx in zip(range(0, 5), index_list):\n",
    "    df = counts_df[idx[0]:idx[-1]]\n",
    "    #print(df)\n",
    "    label = [w + ': ' + str(n) for w, n in zip(df['words'], df['count'])]\n",
    "    color_l = [color_dict.get(i) for i in df['count']]\n",
    "    x = list(df['count'])\n",
    "    y = list(range(0, 20))\n",
    "\n",
    "    sns.barplot(x = x, y = y, data=df, alpha=0.9, orient='h', ax = axs[0][col], palette=color_l)\n",
    "    axs[0][col].set_xlim(0, n+1)\n",
    "    axs[0][col].set_yticklabels(label, fontsize=12)\n",
    "    #axs[0][col].spines['bottom'].set_color('white')\n",
    "    #axs[0][col].spines['right'].set_color('white')\n",
    "    #axs[0][col].spines['left'].set_color('white')\n",
    "    #axs[0][col].spines['top'].set_color('white')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30\n",
    "pal = list(sns.color_palette(palette='tab10', n_colors=n).as_hex())\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.pie(counts_df[0:30], values='count', names='words', color_discrete_sequence=pal)\n",
    "\n",
    "fig.update_traces(textposition='outside', textinfo='percent+label', hole=.6, hoverinfo='label+percent+name')\n",
    "\n",
    "fig.update_layout(width=800, height=600, margin=dict(t=0, l=0, r=0, b=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fig = px.treemap(counts_df[0:50], path=[px.Constant(\"word counts\"), 'words'],\n",
    "    values = 'count',\n",
    "    color='count',\n",
    "    color_continuous_scale='plasma',\n",
    "    color_continuous_midpoint=np.average(counts_df['count']))\n",
    "\n",
    "fig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import circlify\n",
    "\n",
    "circles = circlify.circlify(counts_df['count'][0:30].tolist(),\n",
    "    show_enclosure=False,\n",
    "    target_enclosure=circlify.Circle(x=0, y=0))\n",
    "\n",
    "n = counts_df['count'][0:30].max()\n",
    "color_dict = get_color_dict('plasma', n, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 9), facecolor='white')\n",
    "ax.axis('off')\n",
    "lim = max(max(abs(circle.x)+ circle.r, abs(circle.y)+circle.r) for circle in circles)\n",
    "plt.xlim(-lim, lim)\n",
    "plt.ylim(-lim, lim)\n",
    "\n",
    "labels = list(counts_df['words'][0:30])\n",
    "counts = list(counts_df['count'][0:30])\n",
    "labels.reverse()\n",
    "counts.reverse()\n",
    "\n",
    "for circle, label, count in zip(circles, labels, counts):\n",
    "    x, y, r = circle\n",
    "    ax.add_patch(plt.Circle((x, y), r, alpha=0.9, color=color_dict.get(count)))\n",
    "    plt.annotate(label + '\\n' + str(count), (x,y), size=12, va='center', ha='center')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b6e8e6da794dbf81e23e7a6fb02998f28e41602754784eb3d89e39a25a3a2d61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
